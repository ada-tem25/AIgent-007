{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69cdf15a",
   "metadata": {},
   "source": [
    "### Google Agent Development Kit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07d79111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Import necessary libraries\n",
    "import os\n",
    "import asyncio\n",
    "from google.adk.agents import Agent\n",
    "#from google.adk.models.lite_llm import LiteLlm # For multi-model support\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.genai import types # For creating message Content/Parts\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "# API Key Configuration\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "#Chosen model\n",
    "MODEL_GEMINI_2_0_FLASH = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2f2a8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tool: get_weather called for city: New York ---\n",
      "{'status': 'success', 'report': 'The weather in New York is sunny with a temperature of 25Â°C.'}\n",
      "--- Tool: get_weather called for city: Paris ---\n",
      "{'status': 'error', 'error_message': \"Sorry, I don't have weather information for 'Paris'.\"}\n"
     ]
    }
   ],
   "source": [
    "def get_weather(city: str) -> dict: #Tool\n",
    "    \"\"\"Retrieves the current weather report for a specified city.\n",
    "\n",
    "    Args:\n",
    "        city (str): The name of the city (e.g., \"New York\", \"London\", \"Tokyo\").\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the weather information.\n",
    "              Includes a 'status' key ('success' or 'error').\n",
    "              If 'success', includes a 'report' key with weather details.\n",
    "              If 'error', includes an 'error_message' key.\n",
    "    \"\"\"\n",
    "    print(f\"--- Tool: get_weather called for city: {city} ---\") # Log tool execution\n",
    "    city_normalized = city.lower().replace(\" \", \"\") # Basic normalization\n",
    "\n",
    "    # Mock weather data\n",
    "    mock_weather_db = {\n",
    "        \"newyork\": {\"status\": \"success\", \"report\": \"The weather in New York is sunny with a temperature of 25Â°C.\"},\n",
    "        \"london\": {\"status\": \"success\", \"report\": \"It's cloudy in London with a temperature of 15Â°C.\"},\n",
    "        \"tokyo\": {\"status\": \"success\", \"report\": \"Tokyo is experiencing light rain and a temperature of 18Â°C.\"},\n",
    "    }\n",
    "\n",
    "    if city_normalized in mock_weather_db:\n",
    "        return mock_weather_db[city_normalized]\n",
    "    else:\n",
    "        return {\"status\": \"error\", \"error_message\": f\"Sorry, I don't have weather information for '{city}'.\"}\n",
    "\n",
    "# Example tool usage (optional test)\n",
    "print(get_weather(\"New York\"))\n",
    "print(get_weather(\"Paris\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84cca069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 'weather_agent_v1' created using model 'gemini-2.0-flash'.\n"
     ]
    }
   ],
   "source": [
    "weather_agent = Agent(\n",
    "    name=\"weather_agent_v1\",\n",
    "    model=MODEL_GEMINI_2_0_FLASH, \n",
    "    description=\"Provides weather information for specific cities.\",\n",
    "    instruction=\"You are a helpful weather assistant. \"\n",
    "                \"When the user asks for the weather in a specific city, \"\n",
    "                \"use the 'get_weather' tool to find the information. \"\n",
    "                \"If the tool returns an error, inform the user politely. \"\n",
    "                \"If the tool is successful, present the weather report clearly.\",\n",
    "    tools=[get_weather], \n",
    ")\n",
    "\n",
    "print(f\"Agent '{weather_agent.name}' created using model '{MODEL_GEMINI_2_0_FLASH}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b910c94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session created: App='weather_tutorial_app', User='user_1', Session='session_001'\n",
      "Runner created for agent 'weather_agent_v1'.\n"
     ]
    }
   ],
   "source": [
    "# --- Session Management ---\n",
    "# Key Concept: SessionService stores conversation history & state.\n",
    "# InMemorySessionService is simple, non-persistent storage for this tutorial.\n",
    "session_service = InMemorySessionService()\n",
    "\n",
    "# Define constants for identifying the interaction context\n",
    "APP_NAME = \"weather_tutorial_app\"\n",
    "USER_ID = \"user_1\"\n",
    "SESSION_ID = \"session_001\" # Using a fixed ID for simplicity\n",
    "\n",
    "# Create the specific session where the conversation will happen\n",
    "session = await session_service.create_session(\n",
    "    app_name=APP_NAME,\n",
    "    user_id=USER_ID,\n",
    "    session_id=SESSION_ID\n",
    ")\n",
    "print(f\"Session created: App='{APP_NAME}', User='{USER_ID}', Session='{SESSION_ID}'\")\n",
    "\n",
    "# --- OR ---\n",
    "\n",
    "# Uncomment the following lines if running as a standard Python script (.py file):\n",
    "\n",
    "# async def init_session(app_name:str,user_id:str,session_id:str) -> InMemorySessionService:\n",
    "#     session = await session_service.create_session(\n",
    "#         app_name=app_name,\n",
    "#         user_id=user_id,\n",
    "#         session_id=session_id\n",
    "#     )\n",
    "#     print(f\"Session created: App='{app_name}', User='{user_id}', Session='{session_id}'\")\n",
    "#     return session\n",
    "\n",
    "# session = asyncio.run(init_session(APP_NAME,USER_ID,SESSION_ID))\n",
    "\n",
    "# --- Runner ---\n",
    "# Key Concept: Runner orchestrates the agent execution loop.\n",
    "runner = Runner(\n",
    "    agent=weather_agent, # The agent we want to run\n",
    "    app_name=APP_NAME,   # Associates runs with our app\n",
    "    session_service=session_service # Uses our session manager\n",
    ")\n",
    "print(f\"Runner created for agent '{runner.agent.name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8f2a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Agent Interaction Function\n",
    "from google.genai import types # For creating message Content/Parts\n",
    "\n",
    "async def call_agent_async(query: str, runner, user_id, session_id):\n",
    "  \"\"\"Sends a query to the agent and prints the final response.\"\"\"\n",
    "  print(f\"\\n>>> User Query: {query}\")\n",
    "\n",
    "  # Prepare the user's message in ADK format\n",
    "  content = types.Content(role='user', parts=[types.Part(text=query)])\n",
    "\n",
    "  final_response_text = \"Agent did not produce a final response.\" # Default\n",
    "\n",
    "  # Key Concept: run_async executes the agent logic and yields Events.\n",
    "  # We iterate through events to find the final answer.\n",
    "  async for event in runner.run_async(user_id=user_id, session_id=session_id, new_message=content):\n",
    "      # You can uncomment the line below to see *all* events during execution\n",
    "      #print(f\"  [Event] Author: {event.author}, Type: {type(event).__name__}, Final: {event.is_final_response()}, Content: {event.content}\")\n",
    "\n",
    "      # Key Concept: is_final_response() marks the concluding message for the turn.\n",
    "      if event.is_final_response():\n",
    "          if event.content and event.content.parts:\n",
    "             # Assuming text response in the first part\n",
    "             final_response_text = event.content.parts[0].text\n",
    "          elif event.actions and event.actions.escalate: # Handle potential errors/escalations\n",
    "             final_response_text = f\"Agent escalated: {event.error_message or 'No specific message.'}\"\n",
    "          # Add more checks here if needed (e.g., specific error codes)\n",
    "          break # Stop processing events once the final response is found\n",
    "\n",
    "  print(f\"<<< Agent Response: {final_response_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77cbf73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Query: What is the weather like in London?\n",
      "--- Tool: get_weather called for city: London ---\n",
      "<<< Agent Response: The weather in London is cloudy with a temperature of 15Â°C.\n",
      "\n",
      "\n",
      ">>> User Query: How about Paris?\n",
      "--- Tool: get_weather called for city: Paris ---\n",
      "<<< Agent Response: I am sorry, I don't have weather information for Paris.\n",
      "\n",
      "\n",
      ">>> User Query: Tell me the weather in New York\n",
      "--- Tool: get_weather called for city: New York ---\n",
      "<<< Agent Response: The weather in New York is sunny with a temperature of 25Â°C.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Run the Initial Conversation\n",
    "\n",
    "# We need an async function to await our interaction helper\n",
    "async def run_conversation():\n",
    "    await call_agent_async(\"What is the weather like in London?\",\n",
    "                                       runner=runner,\n",
    "                                       user_id=USER_ID,\n",
    "                                       session_id=SESSION_ID)\n",
    "\n",
    "    await call_agent_async(\"How about Paris?\",\n",
    "                                       runner=runner,\n",
    "                                       user_id=USER_ID,\n",
    "                                       session_id=SESSION_ID) # Expecting the tool's error message\n",
    "\n",
    "    await call_agent_async(\"Tell me the weather in New York\",\n",
    "                                       runner=runner,\n",
    "                                       user_id=USER_ID,\n",
    "                                       session_id=SESSION_ID)\n",
    "\n",
    "# Execute the conversation using await in an async context\n",
    "await run_conversation()\n",
    "\n",
    "# --- OR ---\n",
    "\n",
    "# Uncomment the following lines if running as a standard Python script (.py file):\n",
    "# import asyncio\n",
    "# if __name__ == \"__main__\":\n",
    "#     try:\n",
    "#         asyncio.run(run_conversation())\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c5fd80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’¬ Conversation live avec ton agent ! (tape 'quit' pour arrÃªter)\n",
      "\n",
      "ðŸ‘‹ Fin de la conversation.\n"
     ]
    }
   ],
   "source": [
    "#Fonction pour converser moi mÃªme avec l'agent\n",
    "async def chat_with_agent():\n",
    "    print(\"\\nðŸ’¬ Conversation live avec ton agent ! (tape 'quit' pour arrÃªter)\\n\")\n",
    "    while True:\n",
    "        user_input = input(\"ðŸ§‘â€ðŸ’» Toi: \").strip()\n",
    "        if user_input.lower() in [\"quit\", \"exit\"]:\n",
    "            print(\"ðŸ‘‹ Fin de la conversation.\")\n",
    "            break\n",
    "        await call_agent_async(\n",
    "            query=user_input,\n",
    "            runner=runner,\n",
    "            user_id=USER_ID,\n",
    "            session_id=SESSION_ID\n",
    "        )\n",
    "\n",
    "await chat_with_agent()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953e2988",
   "metadata": {},
   "source": [
    "## Multi-Agent Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdaa24e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greeting and Farewell tools defined.\n",
      "--- Tool: say_hello called with name: Alice ---\n",
      "Hello, Alice!\n",
      "--- Tool: say_hello called without a specific name (name_arg_value: None) ---\n",
      "Hello there!\n",
      "--- Tool: say_hello called without a specific name (name_arg_value: None) ---\n",
      "Hello there!\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "# Define Tools for Greeting and Farewell Agents\n",
    "def say_hello(name: Optional[str] = None) -> str:\n",
    "    \"\"\"Provides a simple greeting. If a name is provided, it will be used.\n",
    "\n",
    "    Args:\n",
    "        name (str, optional): The name of the person to greet. Defaults to a generic greeting if not provided.\n",
    "\n",
    "    Returns:\n",
    "        str: A friendly greeting message.\n",
    "    \"\"\"\n",
    "    if name:\n",
    "        greeting = f\"Hello, {name}!\"\n",
    "        print(f\"--- Tool: say_hello called with name: {name} ---\")\n",
    "    else:\n",
    "        greeting = \"Hello there!\" # Default greeting if name is None or not explicitly passed\n",
    "        print(f\"--- Tool: say_hello called without a specific name (name_arg_value: {name}) ---\")\n",
    "    return greeting\n",
    "\n",
    "def say_goodbye() -> str:\n",
    "    \"\"\"Provides a simple farewell message to conclude the conversation.\"\"\"\n",
    "    print(f\"--- Tool: say_goodbye called ---\")\n",
    "    return \"Goodbye! Have a great day.\"\n",
    "\n",
    "print(\"Greeting and Farewell tools defined.\")\n",
    "\n",
    "# Optional self-test\n",
    "print(say_hello(\"Alice\"))\n",
    "print(say_hello()) # Test with no argument (should use default \"Hello there!\")\n",
    "print(say_hello(name=None)) # Test with name explicitly as None (should use default \"Hello there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "459cc797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent 'greeting_agent' created using model 'gemini-2.0-flash'.\n",
      "âœ… Agent 'farewell_agent' created using model 'gemini-2.0-flash'.\n"
     ]
    }
   ],
   "source": [
    "# Define Greeting and Farewell Sub-Agents\n",
    "\n",
    "# --- Greeting Agent ---\n",
    "greeting_agent = None\n",
    "greeting_agent = Agent(\n",
    "    # Using a potentially different/cheaper model for a simple task\n",
    "    model = MODEL_GEMINI_2_0_FLASH,\n",
    "    # model=LiteLlm(model=MODEL_GPT_4O), # If you would like to experiment with other models\n",
    "    name=\"greeting_agent\",\n",
    "    instruction=\"You are the Greeting Agent. Your ONLY task is to provide a friendly greeting to the user. \"\n",
    "                \"Use the 'say_hello' tool to generate the greeting. \"\n",
    "                \"If the user provides their name, make sure to pass it to the tool. \"\n",
    "                \"Do not engage in any other conversation or tasks.\",\n",
    "    description=\"Handles simple greetings and hellos using the 'say_hello' tool.\", # Crucial for delegation\n",
    "    tools=[say_hello],\n",
    ")\n",
    "print(f\"âœ… Agent '{greeting_agent.name}' created using model '{greeting_agent.model}'.\")\n",
    "\n",
    "\n",
    "# --- Farewell Agent ---\n",
    "farewell_agent = None\n",
    "farewell_agent = Agent(\n",
    "    # Can use the same or a different model\n",
    "    model = MODEL_GEMINI_2_0_FLASH,\n",
    "    # model=LiteLlm(model=MODEL_GPT_4O), # If you would like to experiment with other models\n",
    "    name=\"farewell_agent\",\n",
    "    instruction=\"You are the Farewell Agent. Your ONLY task is to provide a polite goodbye message. \"\n",
    "                \"Use the 'say_goodbye' tool when the user indicates they are leaving or ending the conversation \"\n",
    "                \"(e.g., using words like 'bye', 'goodbye', 'thanks bye', 'see you'). \"\n",
    "                \"Do not perform any other actions.\",\n",
    "    description=\"Handles simple farewells and goodbyes using the 'say_goodbye' tool.\", # Crucial for delegation\n",
    "    tools=[say_goodbye],\n",
    ")\n",
    "print(f\"âœ… Agent '{farewell_agent.name}' created using model '{farewell_agent.model}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f73e9c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Root Agent 'weather_agent_v2' created using model 'gemini-2.0-flash' with sub-agents: ['greeting_agent', 'farewell_agent']\n"
     ]
    }
   ],
   "source": [
    "# Define the Root Agent with Sub-Agents\n",
    "\n",
    "# Ensure sub-agents were created successfully before defining the root agent.\n",
    "# Also ensure the original 'get_weather' tool is defined.\n",
    "root_agent = None\n",
    "runner_root = None # Initialize runner\n",
    "\n",
    "root_agent_model = MODEL_GEMINI_2_0_FLASH\n",
    "\n",
    "weather_agent_team = Agent(\n",
    "    name=\"weather_agent_v2\", # Give it a new version name\n",
    "    model=root_agent_model,\n",
    "    description=\"The main coordinator agent. Handles weather requests and delegates greetings/farewells to specialists.\",\n",
    "    instruction=\"You are the main Weather Agent coordinating a team. Your primary responsibility is to provide weather information. \"\n",
    "                \"Use the 'get_weather' tool ONLY for specific weather requests (e.g., 'weather in London'). \"\n",
    "                \"You have specialized sub-agents: \"\n",
    "                \"1. 'greeting_agent': Handles simple greetings like 'Hi', 'Hello'. Delegate to it for these. \"\n",
    "                \"2. 'farewell_agent': Handles simple farewells like 'Bye', 'See you'. Delegate to it for these. \"\n",
    "                \"Analyze the user's query. If it's a greeting, delegate to 'greeting_agent'. If it's a farewell, delegate to 'farewell_agent'. \"\n",
    "                \"If it's a weather request, handle it yourself using 'get_weather'. \"\n",
    "                \"For anything else, respond appropriately or state you cannot handle it.\",\n",
    "    tools=[get_weather], # Root agent still needs the weather tool for its core task\n",
    "    sub_agents=[greeting_agent, farewell_agent]\n",
    ")\n",
    "print(f\"âœ… Root Agent '{weather_agent_team.name}' created using model '{root_agent_model}' with sub-agents: {[sa.name for sa in weather_agent_team.sub_agents]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d236f65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting execution using 'await' (default for notebooks)...\n",
      "\n",
      "--- Testing Agent Team Delegation ---\n",
      "Session created: App='weather_tutorial_agent_team', User='user_1_agent_team', Session='session_001_agent_team'\n",
      "Runner created for agent 'weather_agent_v2'.\n",
      "\n",
      ">>> User Query: Hello there!\n",
      "--- Tool: say_hello called without a specific name (name_arg_value: None) ---\n",
      "<<< Agent Response: Hello there!\n",
      "\n",
      "\n",
      ">>> User Query: What is the weather in New York?\n",
      "--- Tool: get_weather called for city: New York ---\n",
      "<<< Agent Response: The weather in New York is sunny with a temperature of 25Â°C.\n",
      "\n",
      "\n",
      ">>> User Query: Thanks, bye!\n",
      "--- Tool: say_goodbye called ---\n",
      "<<< Agent Response: Goodbye! Have a great day.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example Interaction with the Agent Team\n",
    "import asyncio # Ensure asyncio is imported\n",
    "\n",
    "# Ensure the root agent (e.g., 'weather_agent_team' or 'root_agent' from the previous cell) is defined.\n",
    "# Ensure the call_agent_async function is defined.\n",
    "\n",
    "# Check if the root agent variable exists before defining the conversation function\n",
    "root_agent_var_name = 'root_agent' # Default name from Step 3 guide\n",
    "if 'weather_agent_team' in globals(): # Check if user used this name instead\n",
    "    root_agent_var_name = 'weather_agent_team'\n",
    "elif 'root_agent' not in globals():\n",
    "    print(\"âš ï¸ Root agent ('root_agent' or 'weather_agent_team') not found. Cannot define run_team_conversation.\")\n",
    "    # Assign a dummy value to prevent NameError later if the code block runs anyway\n",
    "    root_agent = None # Or set a flag to prevent execution\n",
    "\n",
    "# Only define and run if the root agent exists\n",
    "if root_agent_var_name in globals() and globals()[root_agent_var_name]:\n",
    "    # Define the main async function for the conversation logic.\n",
    "    # The 'await' keywords INSIDE this function are necessary for async operations.\n",
    "    async def run_team_conversation():\n",
    "        print(\"\\n--- Testing Agent Team Delegation ---\")\n",
    "        session_service = InMemorySessionService()\n",
    "        APP_NAME = \"weather_tutorial_agent_team\"\n",
    "        USER_ID = \"user_1_agent_team\"\n",
    "        SESSION_ID = \"session_001_agent_team\"\n",
    "        session = await session_service.create_session(\n",
    "            app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n",
    "        )\n",
    "        print(f\"Session created: App='{APP_NAME}', User='{USER_ID}', Session='{SESSION_ID}'\")\n",
    "\n",
    "        actual_root_agent = globals()[root_agent_var_name]\n",
    "        runner_agent_team = Runner( # Or use InMemoryRunner\n",
    "            agent=actual_root_agent,\n",
    "            app_name=APP_NAME,\n",
    "            session_service=session_service\n",
    "        )\n",
    "        print(f\"Runner created for agent '{actual_root_agent.name}'.\")\n",
    "\n",
    "        # --- Interactions using await (correct within async def) ---\n",
    "        await call_agent_async(query = \"Hello there!\",\n",
    "                               runner=runner_agent_team,\n",
    "                               user_id=USER_ID,\n",
    "                               session_id=SESSION_ID)\n",
    "        await call_agent_async(query = \"What is the weather in New York?\",\n",
    "                               runner=runner_agent_team,\n",
    "                               user_id=USER_ID,\n",
    "                               session_id=SESSION_ID)\n",
    "        await call_agent_async(query = \"Thanks, bye!\",\n",
    "                               runner=runner_agent_team,\n",
    "                               user_id=USER_ID,\n",
    "                               session_id=SESSION_ID)\n",
    "\n",
    "    # --- Execute the `run_team_conversation` async function ---\n",
    "    # Choose ONE of the methods below based on your environment.\n",
    "    # Note: This may require API keys for the models used!\n",
    "\n",
    "    # METHOD 1: Direct await (Default for Notebooks/Async REPLs)\n",
    "    # If your environment supports top-level await (like Colab/Jupyter notebooks),\n",
    "    # it means an event loop is already running, so you can directly await the function.\n",
    "    print(\"Attempting execution using 'await' (default for notebooks)...\")\n",
    "    await run_team_conversation()\n",
    "\n",
    "    # METHOD 2: asyncio.run (For Standard Python Scripts [.py])\n",
    "    # If running this code as a standard Python script from your terminal,\n",
    "    # the script context is synchronous. `asyncio.run()` is needed to\n",
    "    # create and manage an event loop to execute your async function.\n",
    "    # To use this method:\n",
    "    # 1. Comment out the `await run_team_conversation()` line above.\n",
    "    # 2. Uncomment the following block:\n",
    "    \"\"\"\n",
    "    import asyncio\n",
    "    if __name__ == \"__main__\": # Ensures this runs only when script is executed directly\n",
    "        print(\"Executing using 'asyncio.run()' (for standard Python scripts)...\")\n",
    "        try:\n",
    "            # This creates an event loop, runs your async function, and closes the loop.\n",
    "            asyncio.run(run_team_conversation())\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "    \"\"\"\n",
    "\n",
    "else:\n",
    "    # This message prints if the root agent variable wasn't found earlier\n",
    "    print(\"\\nâš ï¸ Skipping agent team conversation execution as the root agent was not successfully defined in a previous step.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
